---
layout: post
title: "An Allocation Profiler for OCaml Bytecode Interpreter"
date: 2015-09-23 09:51:30
categories: [ocaml, profiling]
---

This post describes a simple flat allocation profiler for OCaml 4.02 bytecode
interpreter.

OCaml is a strongly typed functional language with automatic memory management.
Automatic memory management alleviates the need to manually deal with memory
memory management, and by construction, avoids a large class of bugs. However,
abstractions are not free in OCaml. Unlike [MLton](http://mlton.org/), a
whole-program optimizing Standard ML compiler, which I used to hack on in [an
earlier life](http://multimlton.cs.purdue.edu/mML/Welcome.html), in OCaml, one
needs to be particularly aware of the cost of introducing abstractions such as
higher-order functions and modules. This is often at odds with desirable
programming patterns one tends to embrace in a higher-order modular functional
language. Writing performance sensitive code in OCaml remains a skill that is
acquired gradually through experience.

There are of course, excellent
[resources](https://janestreet.github.io/ocaml-perf-notes.html)
[available](https://ocaml.org/learn/tutorials/performance_and_profiling.html)
to understand the performance implications of OCaml abstractions. However,
often times, I simply need a way to profile and uncover performance bottlenecks
in my program, before I can apply any targeted optimizations. Profiling along
the following three axes are particularly useful: *time*, *counts* and
*allocations*. OCaml has [good support for two of
these](http://caml.inria.fr/pub/docs/manual-ocaml/profil.html). While `ocamlcp`
with `ocamlprof` gives you count profile, one can use the standard Unix
profiler `gprof` for time profiling. However, these do not necessarily help
with identifying the cost of abstractions, for which one needs an allocation
profiler[^1].

#The state of allocation profiling in OCaml

While allocation profiler is not part of the standard OCaml distribution,
several alternatives do exist. [Memprof](http://memprof.typerex.org/) from
[OCamlPro](http://www.ocamlpro.com/) provides *"non-intrusive memory profiler
for OCaml applications"*, with a simple online version and a commercial version
with fine-grained tracing. Mark Shinwell has an [allocation profiler for OCaml
4.02](https://github.com/mshinwell/ocaml/tree/4.02-allocation-profiling) native
code programs generated by `ocamlopt`. Unfortunately, neither of these options
were suitable for me as the [Multicore
OCaml](https://github.com/ocamllabs/ocaml-multicore) currently only supports
bytecode compilation, and has a
[markedly](http://www.lpw25.net/ocaml2014-abs.pdf)
[different](http://www.cl.cam.ac.uk/~sd601/papers/multicore_slides.pdf)
[GC](https://www.youtube.com/watch?v=FzmQTC_X5R4). So I decided to implement my
own for the [multicore
compiler](https://github.com/kayceesrk/ocaml-multicore/tree/profile-alloc).
Since the allocation profiler will be useful in general, I have also ported it
to [OCaml 4.02](https://github.com/kayceesrk/ocaml/tree/4.02-profile-alloc).
This post talks about the vanilla OCaml allocation profiler.

#Bytecode allocation profiler

The idea of this allocation profiler is to record the allocations and associate
them with the position in the code where the corresponding block or closure was
allocated. In particular, we do not record the call stack that led to the
allocation point, which would have provided us a more accurate picture. One can
get pretty far with just the flat profile. Running the bytecode program under
the modified interpreter produces a profile, which is then analyzed offline.

The bytecode interpreter of OCaml is remarkably simple, as is the patch for the
allocation profiler. In this section, I will detail the implementation of the
profiler. If you are interested in just using the profiler, do skip right to
the [instructions](#instructions).

When the bytecode is loaded by the interpreter in
[`caml_load_code`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/fix_code.c#L50),
it allocates an array for the bytecode. `caml_start_code` points to the start
of this array. The program counter
[`pc`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L195)
is a pointer into this array. We maintain a distinct code pointer
[`profile_pc`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L188)
that always points to the instruction and never its operands. The offset of
`profile_pc` from `caml_start_code` uniquely identifies a instruction in the
bytecode executable. We will use this offset to record the allocation points.

We allocate an array
[`caml_profile_counts`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/startup.c#L418)
of unsigned integers whose length is equal to the length of the code, into
which we will store the allocation counts. There are two main ways in which
OCaml allocates memory;
[`Alloc_small`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/caml/memory.h#L71)
for allocating in minor heap, and
[`caml_alloc_shr`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/memory.c#L405)
for allocating in major heap. We modify both to record the allocations at a
given instruction. We modify
[`interp.c`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c)
to update `profile_pc` for instructions which potentially allocate. Allocations
for arrays and strings are performed in their corresponding C functions through
[`caml_alloc`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/alloc.c#L30).
Such allocations are covered by recording the instruction in
[`Setup_for_c_call`](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L69).

`caml_alloc_shr` is also used by the GC for promoting live minor heap objects
to major heap at the end of a minor GC cycle. Allocations by GC is ignored by
resetting `profile_pc` to `NULL` before minor collections. Hence, the profiler
only counts allocations by the mutator. Finally, the interpreter [outputs the
profile](https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/startup.c#L450)
at the end of execution of the program.

<div id="instructions"> </div>
#Using the profiler

In order to use the profiler, compile the OCaml programs with the bytecode
compiler `ocamlc` with `-g` option to record the debugging information. This
will be used to interpret the profile. When using `ocamlbuild` it is necessary
to compile and link with `-g` (with `-cflag -g -lflag -g`).

First, get OCaml 4.02 with the allocation profiler, and build it using
[`opam-compiler-conf`](https://github.com/gasche/opam-compiler-conf):

{% highlight bash %}
$ git clone https://github.com/kayceesrk/ocaml
$ cd ocaml
$ git checkout 4.02-profile-alloc
$ opam compiler-conf configure
$ make world.opt
$ opam compiler-conf install
{% endhighlight %}

Let us profile the [Eight
Queens](http://caml.inria.fr/pub/old_caml_site/Examples/oc/basics/queens.ml)
program. Profiling is enabled by setting the `CAML_PROFILE_ALLOC` to the output
filename of the profile.

{% highlight bash %}
$ wget http://caml.inria.fr/pub/old_caml_site/Examples/oc/basics/queens.ml
$ ocamlc -o queens -g queens.ml
$ CAML_PROFILE_ALLOC=queens.preprof ./queens
Chess boards's size ? 8
The 8 queens problem has 92 solutions.

Do you want to see the solutions <n/y> ? n
$ ./tools/allocprof queens.preprof > queens.prof
$ head -n5 queens.prof
Total: 80,433 words
Instr   Words   % of total
-----   -----   ----------
2488    31440   39.09%
27681   31440   39.09%
{% endhighlight %}

`allocprof` is a small python script that post-processes the profile. The
post-processed profile shows the total number of words allocated, and is
followed by the instruction number, words allocated and the percentage of total
allocation that it represents. The instruction number can be linked back to the
source code by dumping the bytecode executable with `dumpobj`.

{% highlight bash %}
$ ./tools/dumpobj queens > queens.dumpobj
$ vim queens.prof queens.dump queens.ml
{% endhighlight %}

<img src="{{ site.url }}/assets/queens-profile-alloc.png" alt="Profiling 8 queens"/>

We can see that the program spent 39.09% of allocations for appending to lists
in `queens.ml` line 61. For the curious, the other 39.09% was spent in
`List.map` function.


# Dealing with early termination

<div id="earlytermination"> </div>

The profiler normally writes out the profile at the end of the standard program
termination, when the interpreter has run to completion. However, programs may
terminate early by explicitly invoking `exit`. In such cases, the runtime does
not get a chance to output the profile. Hence, a function `output_profile: unit
-> unit` is provided to explicitly request the profile to be written out to the
filename provided in `CAML_PROFILE_ALLOC`. The following example illustrates
the use case in a program that uses the `Async` library:

{% highlight ocaml %}
(* foo.ml *)
open Core.Std
open Async.Std

let main () =
  printf "Hello!\n";
  (* Without this call, profile isn't written out *)
  output_profile ();
  return ()

let () =
  Command.async_basic
    ~summary:"foo"
    Command.Spec.(empty)
    main
  |> Command.run
{% endhighlight %}

The program is compiled and run as follows:

{% highlight bash %}
$ ocamlbuild -use-ocamlfind foo.byte -package core -package async -tag thread -tag debug
Finished, 3 targets (0 cached) in 00:00:00.
$ CAML_PROFILE_ALLOC=foo.preprof ./foo.byte
Hello!
$ ls foo.preprof
foo.preprof
{% endhighlight %}

Thanks to [trevorsummerssmith](https://github.com/trevorsummerssmith) for the
motivation and the example.

# Conclusion

The allocation profiler has been quite useful for optimizing small programs. It
would be interesting to see whether it scales to larger ones. Also, here is my
(non-exhaustive) wish list of features:

* Improve tooling. Avoid the need to manually search through text files.
* Record stack allocation. This is especially important in multicore OCaml
	[since stacks are heap allocated](http://kcsrk.info/#ocaml15).
* Record the call stack information for allocations to get an informative profile.
* Dump the profile every few milliseconds to study the allocation behavior of
	programs over time.
* Save the [location information in the object
	header](https://ocaml.org/meetings/ocaml/2013/proposals/profiling-memory.pdf)
	and dump the heap at every GC to catch space leaks.

[^1]: Profiling for time does give you the time that the program spends in garbage collection functions such as minor GC cycles and major GC slices, but are not helpful for pinpointing allocation bottlenecks.
